[
  {
    "objectID": "til/posts/2025-01-26-til-notes-quotes-links-credibility-blogs/index.html",
    "href": "til/posts/2025-01-26-til-notes-quotes-links-credibility-blogs/index.html",
    "title": "Notes on link blogs and more frequent blog posting",
    "section": "",
    "text": "Background\nI’ve really been focusing on developing a daily writing habit. As a result, I’ve been actively generating ideas on how to more frequently publish blog content. My biggest mental hurdle for turning posts around is a deeply embedded feeling that every piece of writing I produce needs to be polished prose, and everything included needs to be absent of error.\n\n\nLinks and thoughts on link blogging\nI recently came across this quote from an interview with Simon Willison on the Real Python podcast with Christopher Bailey (the quote is mentioned around 10m08s):\n\nCredibility is accumulated over time, and it doesn’t take much, like a link blog about a subject run that for six months and you will become one of the top 0.1% people on earth with credibility on that subject just from publishing a few notes and linking to a bunch of things about it.\n\nI found Willison’s statement motivating, inspiring, and a little freeing. It made me reconsider portions of my own blog and what’s their aim. This is my little corner the internet, and I set the expectations and rules of this site.\nCertainly, I believe there is room for more formal, well thought-out forms of writing, like you can read in the blog section of my site. However, I also see the Today I Learned (TIL) section of my site being more like a link blog, a scratch-pad of sorts, and at times a research notebook on topics I’m learning about. Learning is a messy endeavour some times, so why does every piece of writing from it need to be tidy? It doesn’t.\n\n\nMini-blogging and open-source ecosystems\nKelli Bodwin addressed these same ideas during her posit::conf(2024) talk. The talk contained a call to action for attendees to produce more content, even if they weren’t fully formed topics or ideas. Just sharing what you’ve currently learned or are working on strengthens open-source ecosystems and makes them more sustainable. David Robinson’s Rstudio::conf(2019) keynote The unreasonable effectiveness of public work was also referenced, which I have queued up to watch later. Although I suggest listening to Bodwin’s entire talk, you can hear more about these specific ideas around 13m20s.\nWho knows where these thoughts may lead. I’m still learning, which is the most important.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@misc{berke2025,\n  author = {Berke, Collin K},\n  title = {Notes on Link Blogs and More Frequent Blog Posting},\n  date = {2025-01-26},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBerke, Collin K. 2025. “Notes on Link Blogs and More Frequent Blog\nPosting.” January 26, 2025."
  },
  {
    "objectID": "now.html",
    "href": "now.html",
    "title": "Now",
    "section": "",
    "text": "A now page, why?"
  },
  {
    "objectID": "now.html#projects-im-working-on",
    "href": "now.html#projects-im-working-on",
    "title": "Now",
    "section": "Projects I’m working on",
    "text": "Projects I’m working on\n\nTransitioning to LazyVim\nAs of my last update, I decided to burn down my Neovim setup and start over. I was in search of something more enjoyable and manageable to work with. I came across LazyVim and started to really enjoy it. Out of the box it had sane defaults and configurations, so the setup was minimal and I’ve found it more enjoyable to work with. LazyVim Extras also make it easy to install and configure different plugins.\n\n\nBlogging more\nI’m attempting to increase the publishing of my blog posts. I was following a cadance of roughly posting every month. I want to bump this up to two a month, with a stretch goal being every week. The hardest parts are being realistic with myself, identifying shorter post topics to write about, and being kinder to myself. Writing posts with a tighter turn-around means embracing progress over perfection.\n\n\nThinking about the use of data and organizational culture\nMore and more often I’m being tasked with stratigizing how to improve the role and impact data has within an organization. These are not easy questions to answer. I’ve been doing a lot of exploring and experimentation. If anyone has any suggestions, let’s chat.\nIf you’re interested in what I’ve focused on in the past, check out my past updates"
  },
  {
    "objectID": "now.html#books-im-reading",
    "href": "now.html#books-im-reading",
    "title": "Now",
    "section": "Books I’m reading",
    "text": "Books I’m reading"
  },
  {
    "objectID": "now.html#a-list-of-books-ive-read-ever-since-ive-started-keeping-track",
    "href": "now.html#a-list-of-books-ive-read-ever-since-ive-started-keeping-track",
    "title": "Now",
    "section": "A list of books I’ve read (ever since I’ve started keeping track)",
    "text": "A list of books I’ve read (ever since I’ve started keeping track)\n\nPractical SQL, 2nd Edition: A Beginner’s Guide to Storytelling with Data by Anthony DeBarros\nI’m currently working with another collegue to sharpen and practice our SQL skills. Although I’m up-to-date on most of the basics and am usually pretty good at completing straight-forward queries, it was a good time to focus and become even more proficient with the language. So, we picked up this book to learn more.\n\n\nR for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\nCurrently, I’m leading another Data Science Learning Community bookclub meeting for this book. I haven’t read the second edition yet, so I’m excited to see and learn what’s new.\n\n\nWith the Old Breed: At Peleliu and Okinawa by E.B. Sledge\nThis is a personal read I pick up from time to time. I finished watching the HBO miniseries Band of Brothers and The Pacific, which were based on first hand accounts in books like this. With the Old Breed is a first-hand account of one serviceman’s experience on the frontline during operations in the Pacific Theater, specifically in Peleliu and Okinawa, during World War II. It’s unfathomable to comprehend the experiences and hardships many endured. Reading it has made me more deeply appreciate the sacrafices men and women of the armed services make for the United States of America.\n\n\nProfessional development reads\n\nMachine Learning with R - Fourth Edition by Brett Lantz\n\n\nPractical Tableau by Ryan Sleeper\n\n\nHBR Guide to Making Every Meeting Matter from the Harvard Business Review\n\n\nThe Checklist Manifesto: How to Get Things Right by Atul Gawande\n\n\nTidy Modeling with R by Max Kuhn and Julia Silge\n\n\nPython for Data Analysis by Wes McKinney\n\n\nEngineering Production-Grade Shiny Apps by Colin Fay, Sébastien Rochette, Vincent Guyader, and Cervan Girard\n\n\nAdvanced R by Hadley Wickham. Check out past book club meeting recordings here.\n\n\nR Packages by Hadley Wickham and Jenny Bryan. Check out past book club meeting recordings here.\n\n\nVim help files maintained by Carlo Teubner\n\n\nMastering Ubuntu by Jay LaCroix\n\n\nGoogle BigQuery: The Definitive Guide by Valliappa Lakshmanan and Jordan Tigani\n\n\nMastering Shiny by Hadley Wickham. Check out the past book club meeting recordings here.\n\n\nR for Data Science by Hadley Wickham and Garrett Grolemund. Check out the past book club meeting recordings here.\n\n\nDocker Deep Dive by Nigel Poulton\n\n\n\nPersonal reads\n\nThe Currents of Space (Galactic Empire 2) by Issac Asimov\n\n\nThe Stars, Like Dust (Galactic Empire 1) by Issac Asimov\n\n\nRobots and Empire (The Robot Series 4) by Issac Asimov\n\n\nThe Robots of Dawn (The Robot Series 3) by Isaac Asimov\n\n\nThe Naked Sun (The Robot Series Book 2) by Isaac Asimov\n\n\nThe Caves of Steel (The Robot Series Book 1) by Isaac Asimov\n\n\nI, Robot by Isaac Asimov\n\n\nLeviathan Falls (The Expanse book 9) by James S.A. Corey\n\n\nTiamat’s Wrath (The Expanse book 8) by James S.A. Corey\n\n\nPersepolis Rising (The Expanse book 7) by James S.A. Corey\n\n\nBabylon’s Ashes (The Expanse book 6) by James S.A. Corey\n\n\nNemesis Games (The Expanse book 5) by James S.A. Corey\n\n\nCibola Burn (The Expanse book 4) by James S.A. Corey\n\n\nAbaddon’s Gate (The Expanse book 3) by James S.A. Corey\n\n\nCaliban’s War (The Expanse book 2) by James S.A. Corey\n\n\nLeviathon Wakes (The Expanse book 1) by James S.A. Corey\n\n\nThe Galaxy, and the Ground Within: A Novel (Wayfarers 4) by Becky Chambers\n\n\nRecord of a Spaceborn Few (Wayfarers 3) by Becky Chambers\n\n\nA Closed and Common Orbit (Wayfarers 2) by Becky Chambers\n\n\nThe Long Way to a Small, Angry Planet (Wayfarers 1) by Becky Chambers\n\n\nLast of the Breed by Louis L’Amour\n\n\nProject Hail Mary by Andy Weir\n\n\nFirebreak by Nicole Kornher-Stace\n\n\nDune Messiah by Frank Herbert\n\n\nDune by Frank Herbert\n\n\nThe Martian: A Novel by Andy Weir"
  },
  {
    "objectID": "til/index.html",
    "href": "til/index.html",
    "title": "Today I Learned",
    "section": "",
    "text": "Here you’ll find posts related to things I’ve learned recently.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on identifying explicit and implicit missing values\n\n\n\n\n\n\ntil\n\n\nnotes\n\n\nlinks\n\n\ndata wrangling\n\n\n\nHighlights from the DSLC book club discussion of Chapter 18: Missing values from R4DS\n\n\n\n\n\nFeb 1, 2025\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on the use and management of GitHub projects\n\n\n\n\n\n\ntil\n\n\nnotes\n\n\nlinks\n\n\nproductivity\n\n\nproject management\n\n\ngithub\n\n\n\nLearning how to take project management to the next level\n\n\n\n\n\nJan 27, 2025\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on link blogs and more frequent blog posting\n\n\n\n\n\n\ntil\n\n\nnotes\n\n\nlinks\n\n\nquotes\n\n\nblogging\n\n\n\nSome notes, quotes, and links about writing more and sharing your work\n\n\n\n\n\nJan 26, 2025\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nUse list2env() or glue::glue_data() to use a set of elements from a tibble in a string\n\n\n\n\n\n\ntil\n\n\nbase r\n\n\ndata wrangling\n\n\n\nNeed an easy way to access a set of elements from a tibble for string interpolation? Here’s two examples\n\n\n\n\n\nDec 30, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nSeparate character strings into rows and columns using tidyr functions\n\n\n\n\n\n\ntil\n\n\ntidyr\n\n\ndata wrangling\n\n\n\nNeed to separate strings? Use the separate_* family of functions\n\n\n\n\n\nDec 27, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nSummarize logical vectors to calculate numeric summaries\n\n\n\n\n\n\ntil\n\n\ndata wrangling\n\n\nlogical vectors\n\n\nsummary statistics\n\n\n\nNeed proportion and count summaries from a logical vector? Use mean() and sum()\n\n\n\n\n\nDec 8, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nUse base::dput() to easily create and save objects\n\n\n\n\n\n\nproductivity\n\n\nvim\n\n\ntesting\n\n\ndata wrangling\n\n\n\nNeed to create and store an object quickly, use this trick\n\n\n\n\n\nFeb 10, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nCombine plots using patchwork\n\n\n\n\n\n\ndata visualization\n\n\n\nNeed to add two or more plots together? Use the patchwork package\n\n\n\n\n\nDec 23, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nUsing base::tempdir() for temporary data storage\n\n\n\n\n\n\ndata wrangling\n\n\nworkflow\n\n\nproductivity\n\n\n\nNeed to store data in a place that’s not persistent, use a temporary directory\n\n\n\n\n\nNov 3, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating correlations with corrr\n\n\n\n\n\n\ndata analysis\n\n\nexploratory analysis\n\n\ndata visualization\n\n\n\nUse the corrr package to calculate and visualize correlations\n\n\n\n\n\nOct 22, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nEdit an older unpushed commit\n\n\n\n\n\n\ngit\n\n\nGitHub\n\n\n\nUse git rebase to edit previous commit messages\n\n\n\n\n\nOct 14, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nFind and replace in Vim\n\n\n\n\n\n\nvim\n\n\nneovim\n\n\nproductivity\n\n\n\nImproving productivity by using Vim’s :substitute command\n\n\n\n\n\nFeb 24, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Collin K. Berke, Ph.D.",
    "section": "",
    "text": "I’m a media research analyst, data enthusiast, and news, sports, and podcast aficianado.\nProfessionally, I use data, audience measurement, and marketing research methods to answer questions on how to best reach and engage audiences–towards the goal of enriching lives and engaging minds with public media content and services. I am particularly interested in the use and development of open-source statistical software (i.e. R) to achieve this goal, and gaining a broader understanding of the role these tools play in media, digital, and marketing analytics. I also adjunct university courses on the side.\nListening to NPR, watching PBS (especially NOVA), and college football and baseball are my jam.\n\n\nWant to know more about what I’m currently working on, reading, or mastering? Check out the now page.\n\n\n\n\nPh.D. in Media and Communication, 2017, Texas Tech University\nM.A. in Communication Studies, 2013, The University of South Dakota\nBachelor of Science, 2011, The University of South Dakota\n\n\n\n\n\nDigital/Marketing analytics\nAudience measurement\nMedia testing\nR\nData engineering\n\nQuarto and Netlify were used to build and deploy this site. All my blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "index.html#now",
    "href": "index.html#now",
    "title": "Collin K. Berke, Ph.D.",
    "section": "",
    "text": "Want to know more about what I’m currently working on, reading, or mastering? Check out the now page."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Collin K. Berke, Ph.D.",
    "section": "",
    "text": "Ph.D. in Media and Communication, 2017, Texas Tech University\nM.A. in Communication Studies, 2013, The University of South Dakota\nBachelor of Science, 2011, The University of South Dakota"
  },
  {
    "objectID": "index.html#interests",
    "href": "index.html#interests",
    "title": "Collin K. Berke, Ph.D.",
    "section": "",
    "text": "Digital/Marketing analytics\nAudience measurement\nMedia testing\nR\nData engineering\n\nQuarto and Netlify were used to build and deploy this site. All my blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "What’s Worth Your Time: Read, Watch, and Listen\n\n\n\n\n\n\nreflection\n\n\ndata science\n\n\ndata analysis\n\n\nresources\n\n\n\nA curated list of data science, analysis, coding, tech-related, and miscellaneous work I’ve found to be useful and impactful\n\n\n\n\n\nJan 11, 2025\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Hex Update: October, 2024\n\n\n\n\n\n\nthe hex update\n\n\nmedia\n\n\n\nKey insights and what I learned about the media industry as of October 2024\n\n\n\n\n\nNov 2, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow walkthrough: Interacting with Google BigQuery in R\n\n\n\n\n\n\nworkflow\n\n\ntutorial\n\n\nproductivity\n\n\nbigquery\n\n\nsql\n\n\n\nA tutorial on how to use the bigrquery package\n\n\n\n\n\nOct 5, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nMessing with models: k-means clustering of Google Analytics 4 data\n\n\n\n\n\n\nmachine learning\n\n\nunsupervised learning\n\n\nk-means clustering\n\n\n\nA tutorial on how to perform k-means clustering using Google Analytics data\n\n\n\n\n\nSep 14, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Hex Update: June, 2024\n\n\n\n\n\n\nthe hex update\n\n\nmedia\n\n\n\nKey insights and what I learned about the media industry in June 2024\n\n\n\n\n\nJul 10, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nMessing with models: Market basket analysis of online merchandise store data\n\n\n\n\n\n\nmachine learning\n\n\nunsupervised learning\n\n\nassociation rules\n\n\nmarket basket analysis\n\n\n\nA tutorial on how to perform a market basket analysis using Google Analytics data\n\n\n\n\n\nJun 11, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring objects launched into space and gross domestic product\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\ntidytuesday\n\n\nplotly\n\n\nregression\n\n\n\nA contribution to the 2024-04-23 #tidytuesday social data project\n\n\n\n\n\nMay 3, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring data from the Fiscal Sponsor Directory\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\ntidytuesday\n\n\nplotly\n\n\nTableau\n\n\n\nA contribution to the 2024-03-12 #tidytuesday social data project\n\n\n\n\n\nMar 22, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the relationship between trash processed by Mr. Trash Wheel and precipitation\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\ntidytuesday\n\n\nplotly\n\n\nTableau\n\n\n\nA contribution to the 2024-03-05 #tidytuesday social data project\n\n\n\n\n\nMar 12, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the lifespans of historical figures born on a Leap Day\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\ntidytuesday\n\n\nplotly\n\n\nTableau\n\n\n\nA contribution to the 2024-02-27 #tidytuesday social data project\n\n\n\n\n\nMar 5, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring R Consortium ISC Grants\n\n\n\n\n\n\ndata wrangling\n\n\ndata visualization\n\n\ntidytuesday\n\n\nplotly\n\n\nTableau\n\n\n\nA contribution to the 2024-02-20 #tidytuesday social data project\n\n\n\n\n\nFeb 26, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\n30 day tidymodels recipes challenge\n\n\n\n\n\n\nmachine learning\n\n\nfeature engineering\n\n\ntidymodels\n\n\ndata wrangling\n\n\n\nLearning how to use the recipes package, one day at a time\n\n\n\n\n\nJan 1, 2024\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nMessing with models: Learning how to fit a binary classification model using NCAA Big Ten women’s volleyball data\n\n\n\n\n\n\ntutorial\n\n\ntidymodels\n\n\nclassification\n\n\ndecision tree\n\n\nlogistic regression\n\n\n\nUsing tidymodels to predict wins and losses for volleyball matches\n\n\n\n\n\nDec 7, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\n2023 data science rig: Set up and configuration\n\n\n\n\n\n\ntutorial\n\n\n\nOverviewing and reflecting on my current data science setup.\n\n\n\n\n\nJan 29, 2023\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nFlattening Google Analytics 4 data\n\n\n\n\n\n\nBigQuery\n\n\nsql\n\n\ndata wrangling\n\n\n\nLet’s deep dive into working with Google Analytics data stored in BigQuery.\n\n\n\n\n\nSep 20, 2022\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory analysis of Google Analytics 4 data for forecasting models\n\n\n\n\n\n\nforecasting\n\n\n\nExploring Google Analytics 4 data for forecasting models.\n\n\n\n\n\nMar 3, 2022\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nShiny summary tiles\n\n\n\n\n\n\nshiny\n\n\n\nBuilding custom metric summary tiles for Shiny.\n\n\n\n\n\nDec 30, 2021\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\n2021 PBS TechCon: Your Data is Disgusting!\n\n\n\n\n\n\ntalks\n\n\n\nI was fortunate to be invited to present about topics I’m passionate about: tidy data and data pipelines.\n\n\n\n\n\nOct 19, 2021\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing a next and back button in Shiny\n\n\n\n\n\n\nshiny\n\n\n\nTaking the time to understand a challenging question from Mastering Shiny.\n\n\n\n\n\nSep 12, 2021\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\n\n\n\n\n\n\nIntro Post\n\n\n\n\n\n\npersonal\n\n\n\nHello World!, my name is Collin, and this is my blog.\n\n\n\n\n\nApr 2, 2021\n\n\nCollin K. Berke, Ph.D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/2025-01-11-post-data-science-analysis-things-you-should-read-watch-listen/index.html",
    "href": "blog/posts/2025-01-11-post-data-science-analysis-things-you-should-read-watch-listen/index.html",
    "title": "What’s Worth Your Time: Read, Watch, and Listen",
    "section": "",
    "text": "Photo by Cristina Gottardi\n\n\n\nMotivation\nWe’re a week into 2025, and I thought this would be a perfect time for some reflection. Inspired by Tan Ho’s post, I felt compiling a non-exhaustive list of content I’ve enjoyed would be a valuable, useful exercise to kick off the new year. Rather than have these resources sit untouched in my bookmarks, I thought I’d share.\nBelow you will find sections containing curated lists of posts, videos, and other content I’ve found relevant to shaping how I view and approach my work. Much of the content is data science, analysis, technology, career development, and media industry related. Some links are just stuff I’ve found interesting.\nEnjoy!\n\n\nData science, analysis, coding\n\nJenny Bryan: Project-oriented workflow, blog post (~15min read)\n\nThis is one of those pieces that was a paradigm shift in my thinking: self-contained projects. A simple idea with a major impact. In the past, my workflow would be a hodgepodge mess of errant scripts and files. The idea of using some simple conventions to allow my code to work on ‘another computer’ or in an ‘another environment’ was absent. Employing some of the post’s conventions increased my impact, as I was better positioned to share my work with others.\n\nJenny Bryan: Object of type ‘closure’ is not subsettable, YouTube video (53 mins)\n\nIf you work with the R programming language, this video is worth every minute. Learning how to debug code helps you more quickly identify where something is going wrong, determine what is going wrong, and come to a useful solution.\n\nEmily Riederer: RMarkdown Driven Development (RmdDD), blog post (~20 min read)\n\nRmdDD (now QmdDD for some) just works for analysis project development. A straightforward idea: get your entire process into one file, then refactor from there. This is how I generally approach most analysis projects now.\n\nSharla Gelfand: Don’t repeat yourself, talk to yourself! Reporting with R | RStudio(2020), YouTube video (21 mins)\n\nThe key takeaway: think of ways to incorporate structure into your projects that will be helpful the next time you have to complete something. This talk motivated me to be more intentional about project structure and to think about how this structure relates to the impact of my work. There’s power in being nice to your future self and others.\n\nEmily Riederer: Building a team of internal R packages, blog post (~35 mins)\n\nThis post outlines a framework for the development of internal R packages. It frames internal package development as value adds when they act like work colleagues, as they can be helpful to pass along institutional knowledge to others. I aspire to align my internal package development with the suggestions in this post.\n\nDavid Robinson: TidyTuesday live screencasts, YouTube videos (~45mins to ~1hr 15mins)\n\nAlthough David Robinson hasn’t posted a screencast in some time, I still find great value in these, now older, videos. Just watching someone and hearing their thought process as they work to visualize TidyTuesday datasets has been super valuable. I’ve learned a lot from this great resource.\n\nColin Gillespie: Getting the Most Out of Git - posit::conf(2024), YouTube video (21 mins)\n\nDespite this talk’s focus being about Git, I think there’s an even more general lesson shared here. That is, use only what’s needed for the type of project you’re working on and don’t fall into the trap of over burdening yourself and/or team with unneeded complexity. Git and platforms like GitHub have lots of functionality. Critical software is built using these tools, where their use is necessary. But, does my personal project need a DevOps strategy with fully automated testing and app deployment to be successful? Probably not. Can my team get some value from running a few automated tests when they submit a pull request? Maybe, as long as it doesn’t overburden them to get their work done. I struggle with finding the right balance here from time to time. This talk is a freeing reminder to use only what’s needed for the project.\n\n\n\n\nProductivity and project development\n\nJenny Bryan: How to Name Files Like a Normie NormConf YouTube video (5 mins) and GitHub repo (10 mins)\n\nTake five minutes to change your life forever. Regardless if you code or not, everyone who uses a computer needs to develop the skills for naming files. Incorporating some simple naming conventions can be a big productivity boost.\n\nHank Green: The Secret to My Productivity, YouTube video (4 mins). Thanks for sharing, Tan.\n\nI came away with a simple takeaway from this video: get your projects to 80%, share it with the world, and move on to the next. Too often we fall into the trap of attempting to get things perfect. Although striving for perfection makes you feel productive, in reality it slows your ability to learn.\n\n\n\n\nManagement, leadership, and organizational culture\n\nEmilie Schario & Taylor A. Murphy, PhD: Run Your Data Team Like a Product Team, blog post (~20 mins)\n\nI like the framing this post uses to describe how to build and run a data organization. It posits two things data teams need to do to meet their full potential: focus on building a Data Product and view others within your organization as your customers. Indeed, I certainly don’t contend this will work for every data team, but I found it a useful vision for the work my team does.\n\nJD Long: It’s Abstractions All the Way Down… - posit::conf(2023) YouTube recording (1hr 2mins)\n\nThis talk provided a clear framework to better understand where my work fits within a larger organization / network. Framing these ideas in terms of abstractions and providing thoughts on how to understand and work these abstractions has impacted how I approach and view the work within my organization.\n\nHarvard Business Review: HBR Guide to Making Every Meeting Matter, book (~$22).\n\nMeetings are inevitable. In fact, you may be tasked with leading a meeting some time in your career. Some meetings move the needle, others could have been an email. Prepare yourself with some useful techniques to make meetings more impactful, useful.\n\n\n\n\nMedia industry specific (the industry I work in)\n\nDecoder podcast, The Verge (1hr episodes)\n\nIf you’re interested in media or tech, this podcast is for you. Nilay Patel, the host, does a phenomenal job interviewing various CEOs and thought leaders in these industries. Listening to each episode has kept me up to date with the big trends and news happening in these spaces.\n\n\n\n\nPotpourri\nThis section is a miscellaneous collection of stuff I’ve enjoyed but really doesn’t fit into the other categories.\n\nMarketplace weekday radio show and podcast (~30 min episodes)\n\nI like to keep up with business and economic news. Marketplace is an excellent, weekday collection of stories focused on these topics.\n\nPlanet Money, podcast (~30 min episodes) National Public Radio (NPR)\n\nUnderstanding the complexities of the economy can be challenging. Planet Money helps put these topics into perspective.\n\n\n\n\nFinal thoughts\nThe above list is certainly not comprehensive of all the work I’ve found useful and impactful. Some content that has shaped my work and views is not included here. It will expand over time.\nI hope you found at least one useful takeaway. If so, let’s connect and chat about it:\n\nLinkedIn\nGitHub\nBluesky\n\nHere’s to a wonderful start to 2025. Cheers 🎉!\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@misc{berke2025,\n  author = {Berke, Collin K},\n  title = {What’s {Worth} {Your} {Time:} {Read,} {Watch,} and {Listen}},\n  date = {2025-01-11},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nBerke, Collin K. 2025. “What’s Worth Your Time: Read, Watch, and\nListen.” January 11, 2025."
  },
  {
    "objectID": "til/posts/2025-01-27-til-notes-github-projects/index.html",
    "href": "til/posts/2025-01-27-til-notes-github-projects/index.html",
    "title": "Notes on the use and management of GitHub projects",
    "section": "",
    "text": "I recently spent some time focusing on my approach to project management, in hopes of developing skills to be a better team lead. One way I try to manage work is using GitHub Projects.\nBelow are some links and notes about what I’ve recently learned about GitHub projects.\nIn the spirit of attempting to do more link- and micro-blogging, some of these notes may seem disjointed, incomplete, or incohorent. However, it’s what I’ve learned thus far about managing projects in GitHub."
  },
  {
    "objectID": "til/posts/2025-01-27-til-notes-github-projects/index.html#adding-issues-to-a-project",
    "href": "til/posts/2025-01-27-til-notes-github-projects/index.html#adding-issues-to-a-project",
    "title": "Notes on the use and management of GitHub projects",
    "section": "Adding issues to a project",
    "text": "Adding issues to a project\nUse the ‘+ Add item’ to add issues or pull requests to a project. You can then locate the issue via the UI prompts, or you can paste the issue or pull request URL (very helpful). The bulk add issues and pull requests and Adding multiple issues or pull requests from a repository features seem really useful."
  },
  {
    "objectID": "til/posts/2025-01-27-til-notes-github-projects/index.html#adding-fields-to-help-manage-projects",
    "href": "til/posts/2025-01-27-til-notes-github-projects/index.html#adding-fields-to-help-manage-projects",
    "title": "Notes on the use and management of GitHub projects",
    "section": "Adding fields to help manage projects",
    "text": "Adding fields to help manage projects\nAn iteration field seems useful for managing sprint intervals. More about how to setup an iteration field can be found here."
  },
  {
    "objectID": "til/posts/2025-01-27-til-notes-github-projects/index.html#useful-commands-for-managing-issues-and-projects",
    "href": "til/posts/2025-01-27-til-notes-github-projects/index.html#useful-commands-for-managing-issues-and-projects",
    "title": "Notes on the use and management of GitHub projects",
    "section": "Useful commands for managing issues and projects",
    "text": "Useful commands for managing issues and projects\nCreate an issue with an interactive prompt.\ngh issue create\nSometimes you fall into common patterns when creating issues, so command flags are often helpful.\ngh issue create\ngh issue create -a \"@me\" -t \"New project to work on\" -l \"project\"\ngh issue create -a \"@coworker\" -t \"Fix this\" -l \"bug\"\nMore about how to manage issues in a repo via the command line can be found here.\nYou can list all your projects using the following commands:\n# Your projects\ngh project list\n\n# Organizational owned projects\ngh project list --owner owner_of_project\nView the project either in the command line or open it in a web browser.\n# From command-line\ngh project view 5\n\n# Open in web browser\ngh project view 5 --web\nYou can edit the project README by running the following:\ngh project edit 5 --readme \"Here be some info about the project\"\nHowever, this command seems to only allow you to add a new README and not edit it."
  },
  {
    "objectID": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html",
    "href": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html",
    "title": "Notes on identifying explicit and implicit missing values",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)\nlibrary(nycflights13)\nToday I learned more about identifying explicit and missing values in R. During our weekly Data Science Learning Community’s (DSLC) bookclub meeting for the R for Data Science (R4DS) book, I was re-introduced to several methods to identify explicit and implicit missing values. Much of what is covered here comes from Chapter 18: Missing values of the book. I wanted to share what I’ve learned, in hopes I can better remember this information in the future."
  },
  {
    "objectID": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#base-rs-sapply",
    "href": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#base-rs-sapply",
    "title": "Notes on identifying explicit and implicit missing values",
    "section": "Base R’s sapply()\n",
    "text": "Base R’s sapply()\n\nThe first suggestion was to use base R’s sapply() with an anonymous function. There’s two variations: one that identifys the presence of any NAs across the columns. The second provides a count of NAs for each column.\n\nsapply(starwars, function(x) any(is.na(x)))\n\n      name     height       mass hair_color skin_color  eye_color birth_year        sex     gender \n     FALSE       TRUE       TRUE       TRUE      FALSE      FALSE       TRUE       TRUE       TRUE \n homeworld    species      films   vehicles  starships \n      TRUE       TRUE      FALSE      FALSE      FALSE \n\n\n\nsapply(starwars, function(x) sum(is.na(x)))\n\n      name     height       mass hair_color skin_color  eye_color birth_year        sex     gender \n         0          6         28          5          0          0         44          4          4 \n homeworld    species      films   vehicles  starships \n        10          4          0          0          0"
  },
  {
    "objectID": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#purrrmap_df-with-any-and-is.na",
    "href": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#purrrmap_df-with-any-and-is.na",
    "title": "Notes on identifying explicit and implicit missing values",
    "section": "\npurrr::map_df with any() and is.na()\n",
    "text": "purrr::map_df with any() and is.na()\n\nSimilar to the base R approach is the use of purrr::map_df() with an anonymous function. I’m quite partial to this approach, as it’s even more succinct, though it requires purrr as a dependency. However, if you’re already importing the tidyverse into your session, then why not go ahead and use it?\n\nmap_df(starwars, \\(x) any(is.na(x)))\n\n# A tibble: 1 × 14\n  name  height mass  hair_color skin_color eye_color birth_year sex   gender homeworld species films\n  &lt;lgl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;lgl&gt;      &lt;lgl&gt;      &lt;lgl&gt;     &lt;lgl&gt;      &lt;lgl&gt; &lt;lgl&gt;  &lt;lgl&gt;     &lt;lgl&gt;   &lt;lgl&gt;\n1 FALSE TRUE   TRUE  TRUE       FALSE      FALSE     TRUE       TRUE  TRUE   TRUE      TRUE    FALSE\n# ℹ 2 more variables: vehicles &lt;lgl&gt;, starships &lt;lgl&gt;\n\n\n\nmap_df(starwars, \\(x) sum(is.na(x)))\n\n# A tibble: 1 × 14\n   name height  mass hair_color skin_color eye_color birth_year   sex gender homeworld species films\n  &lt;int&gt;  &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;int&gt;     &lt;int&gt;      &lt;int&gt; &lt;int&gt;  &lt;int&gt;     &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n1     0      6    28          5          0         0         44     4      4        10       4     0\n# ℹ 2 more variables: vehicles &lt;int&gt;, starships &lt;int&gt;"
  },
  {
    "objectID": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#dplyrsummarise",
    "href": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#dplyrsummarise",
    "title": "Notes on identifying explicit and implicit missing values",
    "section": "dplyr::summarise()",
    "text": "dplyr::summarise()\nAnother approach involved the use of dplyr’s summarise() along with across(), everything(), and an anonymous function. This approach was meant only to count the amount of missing values within each column.\n\nstarwars |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x))))\n\n# A tibble: 1 × 14\n   name height  mass hair_color skin_color eye_color birth_year   sex gender homeworld species films\n  &lt;int&gt;  &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;int&gt;     &lt;int&gt;      &lt;int&gt; &lt;int&gt;  &lt;int&gt;     &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n1     0      6    28          5          0         0         44     4      4        10       4     0\n# ℹ 2 more variables: vehicles &lt;int&gt;, starships &lt;int&gt;"
  },
  {
    "objectID": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#skimrskim",
    "href": "til/posts/2025-02-01-til-notes-r-identify-missing-values/index.html#skimrskim",
    "title": "Notes on identifying explicit and implicit missing values",
    "section": "skimr::skim()",
    "text": "skimr::skim()\nskimr::skim() was also discussed, though the output is more verbose than the other options. The output contains a sum of the number of missing values within each column. This is certainly the most succinct way to obtain this information, and it provides additional summary information about your data. However, it may be more information then you need to answer your question about the presence of missing values in your data.\n\nskim(starwars)\n\n\nData summary\n\n\nName\nstarwars\n\n\nNumber of rows\n87\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n8\n\n\nlist\n3\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\nname\n0\n1.00\n3\n21\n0\n87\n0\n\n\nhair_color\n5\n0.94\n4\n13\n0\n11\n0\n\n\nskin_color\n0\n1.00\n3\n19\n0\n31\n0\n\n\neye_color\n0\n1.00\n3\n13\n0\n15\n0\n\n\nsex\n4\n0.95\n4\n14\n0\n4\n0\n\n\ngender\n4\n0.95\n8\n9\n0\n2\n0\n\n\nhomeworld\n10\n0.89\n4\n14\n0\n48\n0\n\n\nspecies\n4\n0.95\n3\n14\n0\n37\n0\n\n\n\nVariable type: list\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nn_unique\nmin_length\nmax_length\n\n\n\nfilms\n0\n1\n24\n1\n7\n\n\nvehicles\n0\n1\n11\n0\n2\n\n\nstarships\n0\n1\n16\n0\n5\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nheight\n6\n0.93\n174.60\n34.77\n66\n167.0\n180\n191.0\n264\n▂▁▇▅▁\n\n\nmass\n28\n0.68\n97.31\n169.46\n15\n55.6\n79\n84.5\n1358\n▇▁▁▁▁\n\n\nbirth_year\n44\n0.49\n87.57\n154.69\n8\n35.0\n52\n72.0\n896\n▇▁▁▁▁"
  }
]